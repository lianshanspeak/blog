---
title: postgrsql学习记录
date: 2022-09-13 17:41:32
permalink: /pages/13b87c/
categories:
  - 数据库
  - postgresql
tags:
  - 
---


## 大批量单表导入数据引发性能故障

现象：服务器卡死，但cpu利用率不高，free查看内存耗尽
判断是否有大量数据导入操作，有先删除索引，在进行数据导入

## pg_double_cache

读取数据块的时候会占用2份内存。缓存，就是内存会在os的page cache和数据库的buffer库里面会体现出来。存在内存浪费

### **技术原理**

pg写操作用了buffer IO 的接口，到os层会产生缓存，最后由io子系统写入到块设备里面去，读操作类似

### **影响行业或导致问题**

所有行业，内存浪费
os的buffer IO,调度配置不好的话，对导致大量IO,IO hang，导致checkpoint，和别的的读数据的响应时间

始终要过一次层os cache

### **解决方法**

好处
1.会在os层合并之后在写入，减少总的io次数
2.数据库在重启的时候可以缓冲一下,在发起读请求的时候其实是从os层面cache读出来的，（业务繁忙的时候，挂了，重启的场景）
3.刷盘，checkpoint

避免
无解。配置较大的shared buffer

shared_buffer
设置为物理内存的25%，服务器的内存为8G，故将此选项设置为1G：
shared_buffers = 2048MB

## pg_local_memory

plan cachae

### **背后原理**

sql执行的几个阶段
1解析：有没有语法错误，规整化
2query的rewrit
前面

**解析计划**
执行
在会话里面是私有的

### **影响行业**

1SaaS
2分区超多的场景，要使用长连接的场景
3微服务

### **使用local memory带来的问题**

saas：提供软件服务，有一套独立的schema，服务1w家企业的话有可能有1w个schema，每个schema可能有上万的表或对象，就很多了
一个会话生命周期内访问很多表，数据库对象，就会产生很多的loacl cache就是local 的memory包括plan cache,占用的内存会越来越大，最后导致omm
分区超多，要使用长连接，
频繁更新c端的业务系统通常就有这些特性，比如共享单车数量多，用户多，通过分区提高freeze的效率，一个连接可能到
很多的分区，消耗的内存就很多
微服务
对业务灵活，对于数据库来将，每一个服务都要跟数据库产生连接

### **业务上如何避免这个坑**

1、设置会话的连接生命周期，避免长时间使用过多的对象
2、控制总的连接数
3、避免访问分区过度，原始的即便访问分区，也要把所有的全部touch出来
4、创建一个中间连接池，控制总的连接数，pgbouncer（牺牲短频快）

会引入什么新的问题，产生什么样的牺牲
1.增加复杂度
2.微服务很多的时候控制总连接数

未来
1.内置线程池
2.local memory作成global memory

## pg_log_statement参数

log_statements

有效值none(off),ddl,mod,all
ddl记录数据定义语句，create,alter,drop
mod:所有ddl以及数据修改语句
查看 show log_statement;
修改会话级别
set log_statement = none;

## 大批量单表导入数据引发性能故障

现象：服务器卡死，但cpu利用率不高，free查看内存耗尽
判断是否有大量数据导入操作，有先删除索引，在进行数据导入

pg_double_cache
